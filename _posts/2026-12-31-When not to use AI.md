## When not to use AI.

<i>Published on December 31, 2024 by Michiel Bontenbal. </i>

The progress of Artificial Intelligence (AI) has been very fast the last couple of years. However, AI's still makes a lot of mistakes. In this blogpost I will discuss when not to use AI. 

#### Some examples of AI that makes mistakes.

- Tesla sees the moon
- Self driving taxi's
- Example of Dutch man

#### A risk based approach to using or not using AI's. 

So when should we or should we not use current AI systems? Well, if the risk of a failure does not outweigh the benefits. 

So what is risk? Risk can be defined as follows:

```
Risk = Chance * Impact
```
So a low chance with a very high impact, can still be a large risk. Take for example the self driving car: even if there is a low chance it will hit a child, the death of the child is a very high impact, resulting in a high risk.

Are there low impact AI's? Yes, there are many, such as OCR or translating simple text. 

#### Human Centered AI?

Does that mean that we should not use AI at all in these situations? Well, maybe 'Human Centered AI' could be a practical way forward. In this approach the AI supports a human. For example, it's an AI that detects a spot on a lung photo, but ultimately it is the medical doctor that takes the decision whether the patient has lungcancer or not. 
